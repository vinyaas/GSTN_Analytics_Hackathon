{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler , MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score , f1_score , precision_score , recall_score , roc_auc_score \n",
    "import time\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the datasets\n",
    "pd.reset_option('display.max_columns')\n",
    "x_train = pd.read_csv('../data/X_Train_Data_Input.csv')\n",
    "y_train = pd.read_csv('../data/Y_Train_Data_Target.csv')\n",
    "x_test = pd.read_csv('../data/X_Test_Data_Input.csv')\n",
    "y_test = pd.read_csv('../data/Y_Test_Data_Target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785133, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Column0</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>...</th>\n",
       "      <th>Column12</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad1a67e4cbddc767a3456b0d94299b9e</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>3726.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>0.434190</td>\n",
       "      <td>-0.015603</td>\n",
       "      <td>0.606265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7246d2f76ac0c217ec25e72ea5f014cb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>0.452580</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>1.554998</td>\n",
       "      <td>-0.015574</td>\n",
       "      <td>0.329946</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22ba388e7dd14c13342c49e75fc29dda</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>4543.0</td>\n",
       "      <td>-1.577453</td>\n",
       "      <td>-1.429540</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  Column0  Column1  Column2   Column3  \\\n",
       "0  ad1a67e4cbddc767a3456b0d94299b9e      2.0     2495   3726.0  0.678139   \n",
       "1  7246d2f76ac0c217ec25e72ea5f014cb      0.0     2495   3454.0  0.452580   \n",
       "2  22ba388e7dd14c13342c49e75fc29dda      2.0     2495   4543.0 -1.577453   \n",
       "\n",
       "    Column4   Column5   Column6   Column7   Column8  ...  Column12  Column13  \\\n",
       "0  0.701403 -0.007468  0.434190 -0.015603  0.606265  ...         0         0   \n",
       "1  0.701403 -0.007468  1.554998 -0.015574  0.329946  ...         0         0   \n",
       "2 -1.429540 -0.007469 -0.407939 -0.015607 -0.774979  ...         1         1   \n",
       "\n",
       "   Column14  Column15  Column16  Column17  Column18  Column19  Column20  \\\n",
       "0  0.001351   0.00339       0.0         0       0.0         0         0   \n",
       "1  0.001351   0.00339       0.0         0       0.0         0         0   \n",
       "2  0.001351   0.00339       0.0         0       0.0         0         0   \n",
       "\n",
       "   Column21  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "x_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261712, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Column0</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>...</th>\n",
       "      <th>Column12</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07cf2025382f6325b316e128b1b90999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.554860</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb972eb3a1f8d0d1a13f45e7c07d37d4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1579</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.142149</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee35e164b3ddc25a9f40243b81ad290d</td>\n",
       "      <td>0.0</td>\n",
       "      <td>898</td>\n",
       "      <td>3817.0</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  Column0  Column1  Column2   Column3  \\\n",
       "0  07cf2025382f6325b316e128b1b90999      1.0     1986     53.0  0.678139   \n",
       "1  eb972eb3a1f8d0d1a13f45e7c07d37d4      2.0     1579     12.0  0.678139   \n",
       "2  ee35e164b3ddc25a9f40243b81ad290d      0.0      898   3817.0 -2.028572   \n",
       "\n",
       "    Column4   Column5   Column6   Column7   Column8  ...  Column12  Column13  \\\n",
       "0  0.701403 -0.007469 -0.407939 -0.015607  0.554860  ...         1         1   \n",
       "1  0.701403 -0.007468 -0.407939 -0.015607  0.142149  ...         1         0   \n",
       "2 -1.855728       NaN -0.407939 -0.015607 -0.774979  ...         0         0   \n",
       "\n",
       "   Column14  Column15  Column16  Column17  Column18  Column19  Column20  \\\n",
       "0  0.001351   0.00339       0.0         0       0.0         0         0   \n",
       "1  0.001351   0.00339       0.0         0       0.0         0         0   \n",
       "2       NaN   0.00339       0.0         0       0.0         0         0   \n",
       "\n",
       "   Column21  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "x_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785133, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad1a67e4cbddc767a3456b0d94299b9e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7246d2f76ac0c217ec25e72ea5f014cb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22ba388e7dd14c13342c49e75fc29dda</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  target\n",
       "0  ad1a67e4cbddc767a3456b0d94299b9e       0\n",
       "1  7246d2f76ac0c217ec25e72ea5f014cb       0\n",
       "2  22ba388e7dd14c13342c49e75fc29dda       0"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Data Cleaning</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>PERCENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Column9</th>\n",
       "      <td>732137.0</td>\n",
       "      <td>93.250061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column14</th>\n",
       "      <td>365703.0</td>\n",
       "      <td>46.578478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column5</th>\n",
       "      <td>167180.0</td>\n",
       "      <td>21.293208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column4</th>\n",
       "      <td>127710.0</td>\n",
       "      <td>16.266034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column3</th>\n",
       "      <td>126303.0</td>\n",
       "      <td>16.086829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column15</th>\n",
       "      <td>16456.0</td>\n",
       "      <td>2.095951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column6</th>\n",
       "      <td>3850.0</td>\n",
       "      <td>0.490363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column8</th>\n",
       "      <td>3850.0</td>\n",
       "      <td>0.490363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TOTAL    PERCENT\n",
       "Column9   732137.0  93.250061\n",
       "Column14  365703.0  46.578478\n",
       "Column5   167180.0  21.293208\n",
       "Column4   127710.0  16.266034\n",
       "Column3   126303.0  16.086829\n",
       "Column15   16456.0   2.095951\n",
       "Column6     3850.0   0.490363\n",
       "Column8     3850.0   0.490363\n",
       "Column0        9.0   0.001146\n",
       "ID             NaN        NaN\n",
       "Column1        NaN        NaN\n",
       "Column2        NaN        NaN\n",
       "Column11       NaN        NaN\n",
       "Column10       NaN        NaN\n",
       "Column7        NaN        NaN\n",
       "Column13       NaN        NaN\n",
       "Column12       NaN        NaN\n",
       "Column16       NaN        NaN\n",
       "Column17       NaN        NaN\n",
       "Column18       NaN        NaN\n",
       "Column19       NaN        NaN\n",
       "Column20       NaN        NaN\n",
       "Column21       NaN        NaN"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing values \n",
    "def missing_values(x):\n",
    "    \n",
    "    total = x.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (total/len(x)) * 100\n",
    "    return pd.concat((total , percent) , axis = 1 , keys = ['TOTAL' , 'PERCENT'])\n",
    "\n",
    "miss_values_xtrain = missing_values(x_train)\n",
    "miss_values_xtrain[miss_values_xtrain!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>PERCENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Column9</th>\n",
       "      <td>243853.0</td>\n",
       "      <td>93.176087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column14</th>\n",
       "      <td>121679.0</td>\n",
       "      <td>46.493474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column5</th>\n",
       "      <td>55659.0</td>\n",
       "      <td>21.267271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column4</th>\n",
       "      <td>42710.0</td>\n",
       "      <td>16.319466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column3</th>\n",
       "      <td>42234.0</td>\n",
       "      <td>16.137586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column15</th>\n",
       "      <td>5485.0</td>\n",
       "      <td>2.095815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column6</th>\n",
       "      <td>1234.0</td>\n",
       "      <td>0.471511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column8</th>\n",
       "      <td>1234.0</td>\n",
       "      <td>0.471511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TOTAL    PERCENT\n",
       "Column9   243853.0  93.176087\n",
       "Column14  121679.0  46.493474\n",
       "Column5    55659.0  21.267271\n",
       "Column4    42710.0  16.319466\n",
       "Column3    42234.0  16.137586\n",
       "Column15    5485.0   2.095815\n",
       "Column6     1234.0   0.471511\n",
       "Column8     1234.0   0.471511\n",
       "Column0        2.0   0.000764\n",
       "ID             NaN        NaN\n",
       "Column1        NaN        NaN\n",
       "Column2        NaN        NaN\n",
       "Column11       NaN        NaN\n",
       "Column10       NaN        NaN\n",
       "Column7        NaN        NaN\n",
       "Column13       NaN        NaN\n",
       "Column12       NaN        NaN\n",
       "Column16       NaN        NaN\n",
       "Column17       NaN        NaN\n",
       "Column18       NaN        NaN\n",
       "Column19       NaN        NaN\n",
       "Column20       NaN        NaN\n",
       "Column21       NaN        NaN"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_values_xtest = missing_values(x_test)\n",
    "miss_values_xtest[miss_values_xtest!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **We will be dropping column 9 in both test and train datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop('Column9' , axis = 1 , inplace=True)\n",
    "x_test.drop('Column9' , axis = 1, inplace=True)\n",
    "x_train.drop('ID' , axis = 1 , inplace= True)\n",
    "x_test.drop('ID', axis= 1 , inplace= True)\n",
    "y_train.drop('ID' , axis = 1 , inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Checking the distribution of the missing values for imputation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>419430.000000</td>\n",
       "      <td>617953.000000</td>\n",
       "      <td>657423.000000</td>\n",
       "      <td>658830.000000</td>\n",
       "      <td>768677.000000</td>\n",
       "      <td>781283.000000</td>\n",
       "      <td>781283.000000</td>\n",
       "      <td>785124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000863</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000855</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>0.440757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.291202</td>\n",
       "      <td>1.015255</td>\n",
       "      <td>1.000350</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>1.283393</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>1.056769</td>\n",
       "      <td>1.163275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-832.749615</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1091.545904</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001351</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-0.577162</td>\n",
       "      <td>-0.675216</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001351</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>0.122085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001351</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>-0.367723</td>\n",
       "      <td>0.625528</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.514416</td>\n",
       "      <td>551.421127</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>14.985817</td>\n",
       "      <td>323.992484</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column14        Column5        Column4        Column3  \\\n",
       "count  419430.000000  617953.000000  657423.000000  658830.000000   \n",
       "mean       -0.000863      -0.000367      -0.000855      -0.000210   \n",
       "std         1.291202       1.015255       1.000350       0.999935   \n",
       "min      -832.749615      -0.007469      -1.855728      -2.028572   \n",
       "25%         0.001351      -0.007469      -0.577162      -0.675216   \n",
       "50%         0.001351      -0.007469       0.701403       0.678139   \n",
       "75%         0.001351      -0.007468       0.701403       0.678139   \n",
       "max         8.514416     551.421127       0.701403       0.678139   \n",
       "\n",
       "            Column15        Column6        Column8        Column0  \n",
       "count  768677.000000  781283.000000  781283.000000  785124.000000  \n",
       "mean       -0.000837      -0.000709      -0.000158       0.440757  \n",
       "std         1.283393       0.998984       1.056769       1.163275  \n",
       "min     -1091.545904      -0.407939      -0.774979       0.000000  \n",
       "25%         0.003390      -0.407939      -0.774979       0.000000  \n",
       "50%         0.003390      -0.407939       0.122085       0.000000  \n",
       "75%         0.003390      -0.367723       0.625528       0.000000  \n",
       "max         0.012736      14.985817     323.992484      18.000000  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_columns = ['Column14' , 'Column5' , 'Column4' , 'Column3' , 'Column15' , 'Column6' , 'Column8', 'Column0']\n",
    "x_train[impute_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness:\n",
      " Column14   -639.970050\n",
      "Column5     366.846494\n",
      "Column4      -1.007385\n",
      "Column3      -1.165275\n",
      "Column15   -805.439282\n",
      "Column6       2.589699\n",
      "Column8      86.605312\n",
      "Column0       4.074813\n",
      "dtype: float64\n",
      "Kurtosis:\n",
      " Column14    412518.265513\n",
      "Column5     167500.843046\n",
      "Column4         -0.703438\n",
      "Column3         -0.284689\n",
      "Column15    681366.420964\n",
      "Column6          5.443259\n",
      "Column8      22725.306313\n",
      "Column0         22.506434\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "skewness = x_train[impute_columns].skew()\n",
    "kurtosis = x_train[impute_columns].kurtosis()\n",
    "\n",
    "print(\"Skewness:\\n\", skewness)\n",
    "print(\"Kurtosis:\\n\", kurtosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Extreme Skewness :**  Columns - 14 , 5 , 15 , 6   . *Use median imputation*\n",
    "- **Slight skewness :**   Columns - 3 , 4 , 0 , 8 . *Use mean imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Imputing the remaining missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imputation:\n",
    "    \n",
    "    median_cols = ['Column14' , 'Column5' , 'Column15' , 'Column6']\n",
    "    mean_cols = ['Column3' , 'Column4' , 'Column0' , 'Column8']\n",
    "    #impute mean values for the missing data \n",
    "    def imp_mean(self , x):\n",
    "        for col in self.mean_cols:\n",
    "            x[col] = SimpleImputer(strategy='mean').fit_transform(x[[col]])\n",
    "        return x \n",
    "        \n",
    "    #impute median values for the missing data \n",
    "    def imp_median(self ,x):\n",
    "        for col in self.median_cols:\n",
    "            x[col] = SimpleImputer(strategy='median').fit_transform(x[[col]])\n",
    "        return x\n",
    "        \n",
    "imp = imputation()\n",
    "x_train = imp.imp_mean( x = x_train)\n",
    "x_train = imp.imp_median(x = x_train)\n",
    "x_test = imp.imp_mean( x = x_test)\n",
    "x_test = imp.imp_median(x = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column0     0\n",
       "Column1     0\n",
       "Column2     0\n",
       "Column3     0\n",
       "Column4     0\n",
       "Column5     0\n",
       "Column6     0\n",
       "Column7     0\n",
       "Column8     0\n",
       "Column10    0\n",
       "Column11    0\n",
       "Column12    0\n",
       "Column13    0\n",
       "Column14    0\n",
       "Column15    0\n",
       "Column16    0\n",
       "Column17    0\n",
       "Column18    0\n",
       "Column19    0\n",
       "Column20    0\n",
       "Column21    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Outlier detection***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column14    36.070067\n",
       "Column10    24.057453\n",
       "Column6     22.935222\n",
       "Column7     21.240096\n",
       "Column0     19.815114\n",
       "Column3     17.063861\n",
       "Column4     13.543947\n",
       "Column15    13.055622\n",
       "Column18    13.043268\n",
       "Column17     2.348137\n",
       "Column19     1.875861\n",
       "Column20     0.935128\n",
       "Column8      0.368600\n",
       "Column5      0.302114\n",
       "Column21     0.275749\n",
       "Column16     0.120107\n",
       "Column2      0.026110\n",
       "Column1      0.000000\n",
       "Column13     0.000000\n",
       "Column11     0.000000\n",
       "Column12     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using IQR method to determine the outliers \n",
    "\n",
    "Q1 = x_train.quantile(0.25)\n",
    "Q3 = x_train.quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "outliers = ((x_train<(Q1 - 1.5 * IQR)) | (x_train > (Q3 + 1.5 * IQR)))\n",
    "outliers_percentage = (outliers.sum()/len(x_train)) * 100\n",
    "outliers_percentage.sort_values(ascending=False)\n",
    "\n",
    "#We will do robust scaling for the columns having outliers more than 15 percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Feature Scaling </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Column0': np.float64(0.0), 'Column1': np.float64(0.0), 'Column2': np.float64(0.0), 'Column3': np.float64(0.0), 'Column4': np.float64(0.0), 'Column5': np.float64(0.0), 'Column6': np.float64(0.0), 'Column7': np.float64(0.0), 'Column8': np.float64(0.0), 'Column10': np.float64(0.0), 'Column11': np.float64(0.0), 'Column12': np.float64(0.0), 'Column13': np.float64(0.0), 'Column14': np.float64(0.0), 'Column15': np.float64(0.0), 'Column16': np.float64(0.0), 'Column17': np.float64(0.0), 'Column18': np.float64(0.0), 'Column19': np.float64(0.0), 'Column20': np.float64(0.0), 'Column21': np.float64(0.0)}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import normaltest\n",
    "\n",
    "# Function to check normality for all columns\n",
    "def check_normality(x):\n",
    "    results = {}\n",
    "    for column in x.columns:\n",
    "        stat, p = normaltest(x_train[column].dropna())\n",
    "        results[column] = p\n",
    "    return results\n",
    "\n",
    "normality_results = check_normality(x_train)\n",
    "print(normality_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **So we can see that none of the columns follow normal distribution since p value is zero . so we will be using normalization technique**\n",
    "- **Also we have seen that columns - 14 , 10 , 6 , 7 , 0 , 3 have outliers . So we will be using robust scaling technique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataScaler:\n",
    "    def __init__(self, robust_columns):\n",
    "        self.robust_columns = robust_columns\n",
    "        self.rs = RobustScaler()\n",
    "        self.mm = MinMaxScaler()\n",
    "    \n",
    "    def fit_transform(self, x_train, x_test):\n",
    "        normalize = [i for i in x_train.columns if i not in self.robust_columns]\n",
    "        \n",
    "        for col in self.robust_columns:\n",
    "            x_train[col] = self.rs.fit_transform(x_train[[col]])\n",
    "            x_test[col] = self.rs.transform(x_test[[col]])\n",
    "        \n",
    "        for col in normalize:\n",
    "            x_train[col] = self.mm.fit_transform(x_train[[col]])\n",
    "            x_test[col] = self.mm.transform(x_test[[col]])\n",
    "        \n",
    "        return x_train, x_test\n",
    "\n",
    "robust_columns = ['Column14', 'Column10', 'Column6', 'Column7', 'Column0', 'Column3']\n",
    "scaler = DataScaler(robust_columns)\n",
    "\n",
    "x_train_scaled, x_test_scaled = scaler.fit_transform(x_train, x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Feature Engineering</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will be using 3 Feature Engineering techniques**\n",
    "\n",
    "- **Forward Feature Selection**\n",
    "- **Pearson Correlation Co-efficient**\n",
    "- **Recursive Feature Elimination**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1. Pearson Correlation Co-efficient***\n",
    "\n",
    "The Pearson correlation coefficient measures the linear relationship between two variables. It helps identify highly correlated features, which can be removed to reduce multicollinearity. This improves model performance and interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Column18', 'Column1', 'Column19', 'Column17', 'Column20', 'Column8', 'Column12', 'Column21', 'Column2']\n",
      "Column18    0.727999\n",
      "Column1     0.374542\n",
      "Column19    0.258609\n",
      "Column17    0.248896\n",
      "Column20    0.135516\n",
      "Column8     0.129273\n",
      "Column12    0.128421\n",
      "Column21    0.119171\n",
      "Column2     0.114910\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_x = pd.DataFrame(x_train)\n",
    "df_x['target'] = y_train\n",
    "correlations = df_x.corr()['target'].drop('target') #finds the correlations of all columns to target variable\n",
    "\n",
    "#using abs coz -> in many cases we are interested in magnitude (value) instead of direction (pos/negative)\n",
    "sorted_corr = correlations.abs().sort_values(ascending=False)\n",
    "pc_features = sorted_corr.index[: 9].tolist() #we will be listing top 10 columns based on their correlation\n",
    "print(pc_features)\n",
    "print(sorted_corr[pc_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2. Forward Feature Selection***\n",
    "\n",
    "It starts with no features and iteratively adds the feature that gives the best performance improvement when added to the already selected features. The performance is measured using the accuracy of a decision tree classifier. The function returns the selected features in the order they were added, along with their corresponding scores. The print statement inside the loop provides a step-by-step log of which feature is selected at each step and its corresponding score. This can be helpful for understanding how the feature selection process is progressing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1 : Column18 with score 0.9635056856391759\n",
      "Feature 2 : Column7 with score 0.9699975545637953\n",
      "Feature 3 : Column1 with score 0.973787980681054\n",
      "Feature 4 : Column3 with score 0.9742885309042001\n",
      "Feature 5 : Column5 with score 0.9742885309042001\n",
      "Feature 6 : Column0 with score 0.9742885309042001\n",
      "Feature 7 : Column15 with score 0.9742885309042001\n",
      "Feature 8 : Column6 with score 0.9742885309042001\n",
      "Feature 9 : Column10 with score 0.9742885309042001\n",
      "Feature 10 : Column8 with score 0.9742885309042001\n",
      "Feature 11 : Column13 with score 0.9742885309042001\n",
      "Feature 12 : Column16 with score 0.9742885309042001\n",
      "Selected features: ['Column18', 'Column7', 'Column1', 'Column3', 'Column5', 'Column0', 'Column15', 'Column6', 'Column10', 'Column8', 'Column13', 'Column16']\n",
      "Ordered scores: [0.9635056856391759, 0.9699975545637953, 0.973787980681054, 0.9742885309042001, 0.9742885309042001, 0.9742885309042001, 0.9742885309042001, 0.9742885309042001, 0.9742885309042001, 0.9742885309042001, 0.9742885309042001, 0.9742885309042001]\n"
     ]
    }
   ],
   "source": [
    "max_features = 12\n",
    "selected_fs = []\n",
    "ordered_scores = []\n",
    "\n",
    "for i in range(max_features):\n",
    "    features_left = list(set(x_train.columns) - set(selected_fs))\n",
    "    \n",
    "    best_score = 0\n",
    "    best_feature = ''\n",
    "\n",
    "    for feature in features_left:\n",
    "        temp_selected_features = selected_fs + [feature]\n",
    "        \n",
    "        classifier = AdaBoostClassifier(algorithm='SAMME').fit(x_train[temp_selected_features] , y_train)\n",
    "        y_pred = classifier.predict(x_test[temp_selected_features])\n",
    "        score = accuracy_score(y_test , y_pred)\n",
    "        \n",
    "        if score>best_score:\n",
    "            best_score = score\n",
    "            best_feature = feature\n",
    "            \n",
    "    selected_fs.append(best_feature)\n",
    "    ordered_scores.append(best_score)\n",
    "    \n",
    "    print(f\"Feature {i+1} : {best_feature} with score {best_score}\")\n",
    "\n",
    "print(\"Selected features:\", selected_fs)\n",
    "print(\"Ordered scores:\", ordered_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_features = ['Column18', 'Column7', 'Column1', 'Column3', 'Column5', 'Column0', 'Column15', 'Column6', 'Column10', 'Column8', 'Column13', 'Column16']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***3. Recursive Feature Elimination***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features of xtrain Index(['Column0', 'Column1', 'Column2', 'Column3', 'Column8', 'Column10',\n",
      "       'Column12', 'Column15', 'Column16', 'Column17', 'Column18', 'Column19',\n",
      "       'Column20'],\n",
      "      dtype='object')\n",
      "Selected Features of xtest  Index(['Column0', 'Column1', 'Column2', 'Column3', 'Column8', 'Column10',\n",
      "       'Column12', 'Column15', 'Column16', 'Column17', 'Column18', 'Column19',\n",
      "       'Column20'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Recursice Feature Elimination\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "model = LogisticRegression(max_iter=300 , solver='liblinear')\n",
    "rfe = RFE(model , n_features_to_select=13 , step= 3) #since we have a large dataset we will take step (2- 5)\n",
    "y_train_rfe = np.ravel(y_train.values)\n",
    "rfe.fit(x_train , y_train_rfe)\n",
    "x_train_rfe = rfe.transform(x_train)\n",
    "x_test_rfe = rfe.transform(x_test)\n",
    "\n",
    "selected_features_xtrain = x_train.columns[rfe.support_]\n",
    "selected_features_xtest = x_test.columns[rfe.support_]\n",
    "print(\"Selected Features of xtrain\" , selected_features_xtrain)\n",
    "print(\"Selected Features of xtest \" , selected_features_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_features = selected_features_xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.reshape(-1)\n",
    "y_test = y_test.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Model Training</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *We will be using Decision Tree , Random Forest , Gradient Boost , ADA Boost techniques for building the models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "Feature name : Pearson corellation coefficient\n",
      "----------------------------------\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9988\n",
      "- F1 score: 0.9988\n",
      "- Precision: 0.9988\n",
      "- Recall: 0.9988\n",
      "- Roc Auc Score: 0.9966\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9640\n",
      "- F1 score: 0.9640\n",
      "- Precision: 0.9640\n",
      "- Recall: 0.9640\n",
      "- Roc Auc Score: 0.8943\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9988\n",
      "- F1 score: 0.9988\n",
      "- Precision: 0.9988\n",
      "- Recall: 0.9988\n",
      "- Roc Auc Score: 0.9987\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9688\n",
      "- F1 score: 0.9692\n",
      "- Precision: 0.9696\n",
      "- Recall: 0.9688\n",
      "- Roc Auc Score: 0.9199\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9725\n",
      "- F1 score: 0.9733\n",
      "- Precision: 0.9750\n",
      "- Recall: 0.9725\n",
      "- Roc Auc Score: 0.9519\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9726\n",
      "- F1 score: 0.9734\n",
      "- Precision: 0.9752\n",
      "- Recall: 0.9726\n",
      "- Roc Auc Score: 0.9534\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9685\n",
      "- F1 score: 0.9679\n",
      "- Precision: 0.9676\n",
      "- Recall: 0.9685\n",
      "- Roc Auc Score: 0.8903\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9691\n",
      "- F1 score: 0.9686\n",
      "- Precision: 0.9683\n",
      "- Recall: 0.9691\n",
      "- Roc Auc Score: 0.8939\n",
      "===================================\n",
      "\n",
      "\n",
      "==================================\n",
      "Feature name : Forward Feature Selection\n",
      "----------------------------------\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9930\n",
      "- F1 score: 0.9930\n",
      "- Precision: 0.9931\n",
      "- Recall: 0.9930\n",
      "- Roc Auc Score: 0.9858\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9696\n",
      "- F1 score: 0.9698\n",
      "- Precision: 0.9701\n",
      "- Recall: 0.9696\n",
      "- Roc Auc Score: 0.9180\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9930\n",
      "- F1 score: 0.9930\n",
      "- Precision: 0.9932\n",
      "- Recall: 0.9930\n",
      "- Roc Auc Score: 0.9897\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9742\n",
      "- F1 score: 0.9746\n",
      "- Precision: 0.9753\n",
      "- Recall: 0.9742\n",
      "- Roc Auc Score: 0.9410\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9764\n",
      "- F1 score: 0.9770\n",
      "- Precision: 0.9782\n",
      "- Recall: 0.9764\n",
      "- Roc Auc Score: 0.9580\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9765\n",
      "- F1 score: 0.9772\n",
      "- Precision: 0.9785\n",
      "- Recall: 0.9765\n",
      "- Roc Auc Score: 0.9601\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9741\n",
      "- F1 score: 0.9748\n",
      "- Precision: 0.9760\n",
      "- Recall: 0.9741\n",
      "- Roc Auc Score: 0.9505\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9743\n",
      "- F1 score: 0.9749\n",
      "- Precision: 0.9762\n",
      "- Recall: 0.9743\n",
      "- Roc Auc Score: 0.9521\n",
      "===================================\n",
      "\n",
      "\n",
      "==================================\n",
      "Feature name : Recursive Feature Elimination\n",
      "----------------------------------\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9990\n",
      "- F1 score: 0.9990\n",
      "- Precision: 0.9990\n",
      "- Recall: 0.9990\n",
      "- Roc Auc Score: 0.9970\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9661\n",
      "- F1 score: 0.9660\n",
      "- Precision: 0.9660\n",
      "- Recall: 0.9661\n",
      "- Roc Auc Score: 0.8991\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9990\n",
      "- F1 score: 0.9990\n",
      "- Precision: 0.9990\n",
      "- Recall: 0.9990\n",
      "- Roc Auc Score: 0.9989\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9739\n",
      "- F1 score: 0.9744\n",
      "- Precision: 0.9751\n",
      "- Recall: 0.9739\n",
      "- Roc Auc Score: 0.9411\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9753\n",
      "- F1 score: 0.9759\n",
      "- Precision: 0.9772\n",
      "- Recall: 0.9753\n",
      "- Roc Auc Score: 0.9556\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9752\n",
      "- F1 score: 0.9759\n",
      "- Precision: 0.9774\n",
      "- Recall: 0.9752\n",
      "- Roc Auc Score: 0.9577\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9722\n",
      "- F1 score: 0.9728\n",
      "- Precision: 0.9739\n",
      "- Recall: 0.9722\n",
      "- Roc Auc Score: 0.9421\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9724\n",
      "- F1 score: 0.9730\n",
      "- Precision: 0.9742\n",
      "- Recall: 0.9724\n",
      "- Roc Auc Score: 0.9437\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_sets = {\n",
    "    \n",
    "    'Pearson corellation coefficient' : pc_features , \n",
    "    'Forward Feature Selection' : fs_features , \n",
    "    'Recursive Feature Elimination' : rfe_features\n",
    "}\n",
    "\n",
    "for feature_name , feature_set in feature_sets.items():\n",
    "    print('==================================')\n",
    "    print('Feature name :' , feature_name)\n",
    "    print('----------------------------------')\n",
    "\n",
    "    models = {\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'Gradient Boost': GradientBoostingClassifier(),\n",
    "        'Adaboost': AdaBoostClassifier(algorithm='SAMME')\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(x_train[feature_set], y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred= model.predict(x_train[feature_set])\n",
    "        y_test_pred = model.predict(x_test[feature_set])\n",
    "        \n",
    "        # Training set performance\n",
    "        model_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        model_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "        model_train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "        model_train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "        model_train_rocauc_score = roc_auc_score(y_train, y_train_pred, multi_class='ovr')\n",
    "        \n",
    "        # Test set performance\n",
    "        model_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        model_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "        model_test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "        model_test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "        model_test_rocauc_score = roc_auc_score(y_test, y_test_pred, multi_class='ovr')\n",
    "        \n",
    "        print(model_name)\n",
    "        print('Model performance for Training set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "        print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "        print('----------------------------------')\n",
    "        print('Model performance for Test set')\n",
    "        print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "        print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "        print('='*35)\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Forward Feature Selection** - Gradient Boost Accuracy : 97.65 , ADABoost Accuracy : 97.43\n",
    "- **Recursive Feature Elimination** - Gradient Boost Accuracy : 97.52 (slight overfitting) , ADABoost Accuracy : 97.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will be considering **Forward Feature selection** as our feature selection set ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting training time: 94.11 seconds\n",
      "Adaboost training time: 23.10 seconds\n"
     ]
    }
   ],
   "source": [
    "#Checking the run time of both gradient boost and ada boost algorithm\n",
    "\n",
    "import time \n",
    "\n",
    "#Gradient Boosting \n",
    "start_time = time.time()\n",
    "gradient_boost = GradientBoostingClassifier()\n",
    "gradient_boost.fit(x_train[fs_features] , y_train)\n",
    "gradient_boost_time = time.time() - start_time\n",
    "\n",
    "# Adaboost\n",
    "start_time = time.time()\n",
    "adaboost = AdaBoostClassifier(algorithm='SAMME')\n",
    "adaboost.fit(x_train[fs_features], y_train)\n",
    "adaboost_time = time.time() - start_time\n",
    "\n",
    "print(f\"Gradient Boosting training time: {gradient_boost_time:.2f} seconds\")\n",
    "print(f\"Adaboost training time: {adaboost_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosting Feature Importance\n",
    "gradient_boost_importance = gradient_boost.feature_importances_\n",
    "\n",
    "# Adaboost Feature Importance\n",
    "adaboost_importance = adaboost.feature_importances_\n",
    "\n",
    "# Plot feature importances for Gradient Boosting\n",
    "plt.bar(range(len(gradient_boost_importance)), gradient_boost_importance)\n",
    "plt.title('Gradient Boosting Feature Importances')\n",
    "plt.show()\n",
    "\n",
    "# Plot feature importances for Adaboost\n",
    "plt.bar(range(len(adaboost_importance)), adaboost_importance)\n",
    "plt.title('Adaboost Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- **Gradient Boosting & ADA Boosting** models show the most balanced performance between train & test sets , indicating they are less likely to be overfitting / underfitting . **Random Forest & Decision Tree** shows signs of overfitting .\n",
    "\n",
    "- **Forward Feature Selection** feature set is giving higher accuracy compared to other Feature sets\n",
    "\n",
    "- Considering the training time and interpretability of features we can see that **ADA Boost is generally faster and more easily interpretable**. Also **ADABoost** scales better with larger datasets due to its fast training time which allows us for quick iterations and model updates . It also provides better feature interpretability which allows us to make decisions based on feature selection ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Hyper Parameter Tuning </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **RandomSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [50, 60, 70, 80, 90, 100, 150], 'learning_rate': [0.01, 0.1, 1], 'algorithm': ['SAMME', 'SAMME.R']}\n"
     ]
    }
   ],
   "source": [
    "ada_params = {\n",
    "    'n_estimators' : [50 , 60 , 70 , 80 , 90 , 100 , 150] , \n",
    "    'learning_rate' : [0.01 , 0.1 , 1] , \n",
    "    'algorithm' : ['SAMME' , 'SAMME.R']\n",
    "}\n",
    "print(ada_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10714194\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 42 is smaller than n_iter=100. Running 42 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 42 candidates, totalling 126 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10714194\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'learning_rate': 1, 'algorithm': 'SAMME.R'}\n"
     ]
    }
   ],
   "source": [
    "#Since this is a larger dataset we will be using randomizedsearch cv\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Converting series to dataframe to join the data and extract sample\n",
    "y_df = pd.DataFrame(y_train)\n",
    "y_df.rename(columns={0:'Target'} , inplace=True)\n",
    "# Assuming x_train and y_train are pandas DataFrames or Series\n",
    "sampled_data = x_train[fs_features].join(y_df).sample(frac=0.2, random_state=42)\n",
    "x_train_subset = sampled_data.drop(columns=['Target'])\n",
    "y_train_subset = sampled_data['Target']\n",
    "ada_boost = AdaBoostClassifier()\n",
    "random = RandomizedSearchCV(estimator=ada_boost ,\n",
    "                            param_distributions=ada_params,\n",
    "                            n_iter=100,\n",
    "                            cv = 3,\n",
    "                            verbose=2 ,\n",
    "                            n_jobs= - 1, \n",
    "                            error_score='raise')\n",
    "random.fit(x_train_subset , y_train_subset)\n",
    "best_params = random.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10714194\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9761\n",
      "- F1 score: 0.9768\n",
      "- Precision: 0.8298\n",
      "- Recall: 0.9391\n",
      "- Roc Auc Score: 0.9595\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9761\n",
      "- F1 score: 0.9768\n",
      "- Precision: 0.8287\n",
      "- Recall: 0.9412\n",
      "- Roc Auc Score: 0.9605\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using parameters of randomsearchcv for model training\n",
    "\n",
    "ada= AdaBoostClassifier(n_estimators=100 , learning_rate= 1 , algorithm='SAMME.R')\n",
    "ada.fit(x_train[fs_features] , y_train)\n",
    "y_train_fs = ada.predict(x_train[fs_features])\n",
    "y_test_fs = ada.predict(x_test[fs_features])\n",
    "\n",
    "# Train set performance\n",
    "model_train_accuracy = accuracy_score(y_train, y_train_fs) # Calculate Accuracy\n",
    "model_train_f1 = f1_score(y_train, y_train_fs, average='weighted') # Calculate F1-score\n",
    "model_train_precision = precision_score(y_train, y_train_fs) # Calculate Precision\n",
    "model_train_recall = recall_score(y_train, y_train_fs) # Calculate Recall\n",
    "model_train_rocauc_score = roc_auc_score(y_train, y_train_fs)\n",
    "\n",
    "\n",
    "# Test set performance\n",
    "model_test_accuracy = accuracy_score(y_test, y_test_fs) # Calculate Accuracy\n",
    "model_test_f1 = f1_score(y_test, y_test_fs, average='weighted') # Calculate F1-score\n",
    "model_test_precision = precision_score(y_test, y_test_fs) # Calculate Precision\n",
    "model_test_recall = recall_score(y_test, y_test_fs) # Calculate Recall\n",
    "model_test_rocauc_score = roc_auc_score(y_test, y_test_fs) #Calculate Roc\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    \n",
    "print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "print('----------------------------------')\n",
    "    \n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "\n",
    "    \n",
    "print('='*35)\n",
    "print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomSearchCV** giving a better accuracy of 97.61 with its parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Bayesian Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 20:46:16,580] A new study created in memory with name: no-name-e82aada5-b86e-48ea-9300-781657491bcb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 20:47:11,836] Trial 0 finished with value: 0.9638608995344485 and parameters: {'n_estimators': 60, 'learning_rate': 0.11771097627944141, 'algorithm': 'SAMME'}. Best is trial 0 with value: 0.9638608995344485.\n",
      "[I 2024-10-06 20:49:12,279] Trial 1 finished with value: 0.972719272290411 and parameters: {'n_estimators': 129, 'learning_rate': 0.23659278892330382, 'algorithm': 'SAMME'}. Best is trial 1 with value: 0.972719272290411.\n",
      "[I 2024-10-06 20:50:08,528] Trial 2 finished with value: 0.9731574137532416 and parameters: {'n_estimators': 59, 'learning_rate': 0.3749768693927819, 'algorithm': 'SAMME'}. Best is trial 2 with value: 0.9731574137532416.\n",
      "[I 2024-10-06 20:51:43,592] Trial 3 finished with value: 0.9734045053179148 and parameters: {'n_estimators': 99, 'learning_rate': 0.6257729910827361, 'algorithm': 'SAMME'}. Best is trial 3 with value: 0.9734045053179148.\n",
      "[I 2024-10-06 20:53:48,175] Trial 4 finished with value: 0.9729574478988967 and parameters: {'n_estimators': 129, 'learning_rate': 0.2488687300880031, 'algorithm': 'SAMME'}. Best is trial 3 with value: 0.9734045053179148.\n",
      "[I 2024-10-06 20:55:54,579] Trial 5 finished with value: 0.973689807715516 and parameters: {'n_estimators': 130, 'learning_rate': 0.4381217552999389, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.973689807715516.\n",
      "[I 2024-10-06 20:57:15,083] Trial 6 finished with value: 0.972650494033774 and parameters: {'n_estimators': 88, 'learning_rate': 0.22932398097169043, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.973689807715516.\n",
      "[I 2024-10-06 20:59:15,921] Trial 7 finished with value: 0.9729549006473842 and parameters: {'n_estimators': 129, 'learning_rate': 0.21041618804539408, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.973689807715516.\n",
      "[I 2024-10-06 21:01:24,678] Trial 8 finished with value: 0.9728784805875426 and parameters: {'n_estimators': 138, 'learning_rate': 0.24356032612963457, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.973689807715516.\n",
      "[I 2024-10-06 21:03:09,549] Trial 9 finished with value: 0.9638608995344485 and parameters: {'n_estimators': 114, 'learning_rate': 0.08833543345133298, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.973689807715516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 130, 'learning_rate': 0.4381217552999389, 'algorithm': 'SAMME'}\n"
     ]
    }
   ],
   "source": [
    "#Bayesian Optimization\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 150)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 1.0, log=True)\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['SAMME', 'SAMME'])\n",
    "    \n",
    "    model = AdaBoostClassifier(n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algorithm)\n",
    "    return cross_val_score(model, x_train[fs_features], y_train, cv=5, n_jobs=-1).mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10) #will run 10 trials since the data is huge\n",
    "\n",
    "print(\"Best parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9738\n",
      "- F1 score: 0.9747\n",
      "- Precision: 0.8103\n",
      "- Recall: 0.9426\n",
      "- Roc Auc Score: 0.9598\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9739\n",
      "- F1 score: 0.9748\n",
      "- Precision: 0.8099\n",
      "- Recall: 0.9445\n",
      "- Roc Auc Score: 0.9607\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using parameters of Bayesian Optimization for model training\n",
    "\n",
    "ada_bayesian= AdaBoostClassifier(n_estimators=130 , learning_rate= 0.4381217552999389, algorithm='SAMME')\n",
    "ada_bayesian.fit(x_train[fs_features] , y_train)\n",
    "y_train_hp = ada_bayesian.predict(x_train[fs_features])\n",
    "y_test_hp = ada_bayesian.predict(x_test[fs_features])\n",
    "\n",
    "# Train set performance\n",
    "model_train_accuracy = accuracy_score(y_train, y_train_hp) # Calculate Accuracy\n",
    "model_train_f1 = f1_score(y_train, y_train_hp, average='weighted') # Calculate F1-score\n",
    "model_train_precision = precision_score(y_train, y_train_hp) # Calculate Precision\n",
    "model_train_recall = recall_score(y_train, y_train_hp) # Calculate Recall\n",
    "model_train_rocauc_score = roc_auc_score(y_train, y_train_hp)\n",
    "\n",
    "\n",
    "# Test set performance\n",
    "model_test_accuracy = accuracy_score(y_test, y_test_hp) # Calculate Accuracy\n",
    "model_test_f1 = f1_score(y_test, y_test_hp, average='weighted') # Calculate F1-score\n",
    "model_test_precision = precision_score(y_test, y_test_hp) # Calculate Precision\n",
    "model_test_recall = recall_score(y_test, y_test_hp) # Calculate Recall\n",
    "model_test_rocauc_score = roc_auc_score(y_test, y_test_hp) #Calculate Roc\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    \n",
    "print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "print('----------------------------------')\n",
    "    \n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "\n",
    "    \n",
    "print('='*35)\n",
    "print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Since the RandomSearchCV parameters are giving better results we will go with its parameters**\n",
    "- **We will be using ADA-Boost model and RandomSearchCV for our predictive model :**  \n",
    "  {n_estimators=100 , learning_rate= 1 , algorithm='SAMME.R'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Check for OverFitting</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.97403011 0.97383906 0.97390274 0.97336747 0.97317642 0.97392788\n",
      " 0.97276884 0.97427178 0.97462841 0.97527798]\n",
      "Mean Accuracy: 0.9739190684703001\n",
      "Standard Deviation: 0.000683527271147606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv_model  = AdaBoostClassifier(n_estimators=100 , learning_rate= 1 , algorithm='SAMME')\n",
    "\n",
    "#defining kfold cross validator \n",
    "kf = KFold(n_splits = 10, shuffle=True , random_state=42)\n",
    "\n",
    "#perform cross validation\n",
    "scores = cross_val_score(cv_model , x_train[fs_features] , y_train , cv = kf , scoring='accuracy')\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f'Cross-Validation Accuracy Scores: {scores}')\n",
    "print(f'Mean Accuracy: {scores.mean()}')\n",
    "print(f'Standard Deviation: {scores.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Mean Accuracy** is 0.974 and **Standard Deviation** is 0.00066\n",
    "- ***High Mean Accuracy suggests that the model has maintained a high level of accuracy across all folds***\n",
    "- ***Low Standard Deviation suggests that the performance is stable and not varying much betweem subsets of the data***\n",
    "\n",
    "- *This is a strong sign the model is not overfitting & is generalizing well to unseen data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10714194\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9734376890598432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "x_train_v, X_val, y_train_v, y_val = train_test_split(x_train[fs_features], y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = AdaBoostClassifier(n_estimators=80 , learning_rate= 1 , algorithm='SAMME' , random_state=42)\n",
    "model.fit(x_train_v, y_train_v)\n",
    "\n",
    "# Ensure the validation data is clean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_val = imputer.fit_transform(X_val)\n",
    "\n",
    "val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, val_pred)\n",
    "print(f'Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Validation accuracy - 0.9694** indicates that our model is performing well on validation set . The high accuracy suggests that the model isnt overfitting and is able to perform well on unseen data as well .\n",
    "\n",
    "- **We can conclude that the model isnt overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>MODEL SIMPLIFICATION</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will be removing features with zero importance which offer several advantages while handling large datasets . \n",
    "\n",
    "- **Reduced complexity also faster training and prediction**\n",
    "- **Simplified data preprocessing & Enhances Robustness**\n",
    "- **Easier to explain and Better insights**\n",
    "\n",
    "Removing features streamlines your model , making it more efficient , interpretable & robust ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58930127, 0.04437721, 0.35682907, 0.00949245, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "simp_features = ['Column18','Column7','Column1','Column3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.9738\n",
      "- F1 score: 0.9747\n",
      "- Precision: 0.8103\n",
      "- Recall: 0.9426\n",
      "- Roc Auc Score: 0.9598\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9739\n",
      "- F1 score: 0.9748\n",
      "- Precision: 0.8099\n",
      "- Recall: 0.9445\n",
      "- Roc Auc Score: 0.9607\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using parameters of Bayesian Optimization for model training\n",
    "\n",
    "ada_bayesian= AdaBoostClassifier(n_estimators=130 , learning_rate= 0.4381217552999389, algorithm='SAMME')\n",
    "ada_bayesian.fit(x_train[simp_features] , y_train)\n",
    "y_train_hp = ada_bayesian.predict(x_train[simp_features])\n",
    "y_test_hp = ada_bayesian.predict(x_test[simp_features])\n",
    "\n",
    "# Train set performance\n",
    "model_train_accuracy = accuracy_score(y_train, y_train_hp) # Calculate Accuracy\n",
    "model_train_f1 = f1_score(y_train, y_train_hp, average='weighted') # Calculate F1-score\n",
    "model_train_precision = precision_score(y_train, y_train_hp) # Calculate Precision\n",
    "model_train_recall = recall_score(y_train, y_train_hp) # Calculate Recall\n",
    "model_train_rocauc_score = roc_auc_score(y_train, y_train_hp)\n",
    "\n",
    "\n",
    "# Test set performance\n",
    "model_test_accuracy = accuracy_score(y_test, y_test_hp) # Calculate Accuracy\n",
    "model_test_f1 = f1_score(y_test, y_test_hp, average='weighted') # Calculate F1-score\n",
    "model_test_precision = precision_score(y_test, y_test_hp) # Calculate Precision\n",
    "model_test_recall = recall_score(y_test, y_test_hp) # Calculate Recall\n",
    "model_test_rocauc_score = roc_auc_score(y_test, y_test_hp) #Calculate Roc\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "print('- F1 score: {:.4f}'.format(model_train_f1))\n",
    "    \n",
    "print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "\n",
    "print('----------------------------------')\n",
    "    \n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "\n",
    "    \n",
    "print('='*35)\n",
    "print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
